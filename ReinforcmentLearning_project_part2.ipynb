{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.47054753 0.44459091 ... 0.53608153 0.74222978 0.06254457]\n",
      " [0.17419118 0.         0.98244361 ... 0.3590356  0.30560787 0.33516673]\n",
      " [0.12224103 0.28761012 0.         ... 0.67181377 0.68995107 0.84607762]\n",
      " ...\n",
      " [0.86080136 0.56732811 0.47839141 ... 0.         0.60527849 0.66032519]\n",
      " [0.61543139 0.62544033 0.0268665  ... 0.25022509 0.         0.52538823]\n",
      " [0.47357053 0.99779991 0.127991   ... 0.02558122 0.98169621 0.        ]]\n",
      "[0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.optimize import minimize, Bounds, linprog\n",
    "# Environment parameters\n",
    "K = 1000  # Number of content items\n",
    "u_min = 0.2  # Threshold for content relevance\n",
    "C = int(0.2 * K)  # Number of cached items\n",
    "#C = 2\n",
    "# User model parameters\n",
    "N = 10 # Number of recommended items\n",
    "q = 0.2  # Probability of ending the viewing session\n",
    "alpha = 0.8  # Probability of selecting a recommended item\n",
    "#tradeoff_factor=0.4\n",
    "# Generate random relevance values\n",
    "U = np.random.rand(K, K)\n",
    "np.fill_diagonal(U, 0)  # Set diagonal elements to 0\n",
    "# U = np.array([[0., 0.09709217, 0.95697935, 0.76421269, 0.79379138],\n",
    "#               [0.85679266, 0., 0.73115609, 0.97025111, 0.00706508],\n",
    "#               [0.38327773, 0.27582305, 0., 0.40938946, 0.70918518],\n",
    "#               [0.27415892, 0.89691232, 0.47103534, 0., 0.97776446],\n",
    "#               [0.06699551, 0.96500574, 0.00547615, 0.74654658, 0.]])\n",
    "# U = np.array([[0.0, 0.8, 0.3, 0.6],\n",
    "#               [0.8, 0.0, 0.7, 0.2],\n",
    "#               [0.3, 0.1, 0.0, 0.2],\n",
    "#               [0.6, 0.4, 0.2, 0.0]])\n",
    "print(U)\n",
    "#vector to denote the cost of each state. 1 for non-cached, 0 for cached\n",
    "Cost = [1]*(K-C) +[0]*C   \n",
    "#Cost = [1,0,1,0]\n",
    "random.shuffle(Cost)\n",
    "print(Cost)\n",
    "\n",
    "\n",
    "def normalize_matrix_R(R):\n",
    "    row_sums = R.sum(axis=1)\n",
    "\n",
    "    # New matrix is old matrix divided by row sums\n",
    "    # Use np.newaxis to match the dimensions for broadcasting\n",
    "    R = N*R / row_sums[:, np.newaxis]\n",
    "    return R\n",
    "\n",
    "# R = normalize_matrix_R(U)\n",
    "# print(R.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLateQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[429 488 123 ... 361  17 498]\n",
      " [118 680 109 ... 732 209 343]\n",
      " [685 742 133 ... 471 595 110]\n",
      " ...\n",
      " [281 710 598 ... 490 851  58]\n",
      " [488  36 118 ... 845 648 727]\n",
      " [519 209 129 ... 836 647 831]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def all_recommendations_are_relevant(recommendations,s):\n",
    "    \"\"\"\n",
    "    function to check whether everey recommended state in the racommendation batch is \n",
    "    relevant to s\n",
    "\n",
    "    arguments:\n",
    "    recommendations (tuple of ints): recommendation batch for state s\n",
    "    s (int): current state\n",
    "\n",
    "    returns:\n",
    "    True: if all recommendation are relevant to s\n",
    "    False: otherwise\n",
    "    \"\"\"\n",
    "    for u in recommendations:\n",
    "        if U[s][int(u)]<u_min:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def func(x,Q):\n",
    "        return -np.dot(x , Q )/N\n",
    "\n",
    "def maximize_model(Q,s):\n",
    "    \"\"\"\n",
    "    Function to maximize sum(x_i*1/N*Q(s,i))\n",
    "    arguments:\n",
    "    s (int): current state\n",
    "    Q vector of floats: Q(s,:) values\n",
    "\n",
    "    returns:\n",
    "    max value of functio\n",
    "    argmax of fun\n",
    "    \"\"\"\n",
    "\n",
    "    new_P = np.zeros((K, K), dtype=np.float64) #create a Q value array\n",
    "    # # Print the result\n",
    "    # print(f\"Minimized function value: {result.fun}\")\n",
    "    # print(f\"Argmin: {result.x}\")\n",
    "\n",
    "    \n",
    "    C=-1/N*Q\n",
    "    # Equality constraint for summation: sum(x) = N\n",
    "    A_eq = [[1] * K]\n",
    "    b_eq = [N]\n",
    "\n",
    "    # Bounds for each variable: 0 <= x_j <= 1 and x_i = 0\n",
    "    bounds = [(0, 1) if j != s else (0, 0) for j in range(K)]\n",
    "\n",
    "    # Now use linprog\n",
    "    result = linprog(C, bounds=bounds, A_eq=A_eq, b_eq=b_eq, method='highs')\n",
    "    new_P = result.x\n",
    "    max = -result.fun\n",
    "    return new_P,max\n",
    "\n",
    "\n",
    "\n",
    "def SlateQ(gamma, epsilon,learning_rate):\n",
    "    \"\"\"\n",
    "    Function to perform SlateQ algorithm.\n",
    "\n",
    "    arguments:\n",
    "    gamma (float): discounting factor\n",
    "    epsilon (float): epslilon greedy probability\n",
    "    learning_rate (float): learning rate\n",
    "\n",
    "    returns:\n",
    "    Q (matrix K x K):  martix of state action value function calculated using bellman equation\n",
    "    \"\"\"\n",
    "    Q = np.zeros((K,K)) \n",
    "    P = normalize_matrix_R(U) \n",
    "    #prev_Q = np.zeros((K,K))\n",
    "    t = 0\n",
    "    while True:\n",
    "        s = np.random.randint(K) #random initial state\n",
    "        while True:\n",
    "            if np.random.uniform() < epsilon:  # Explore if e(t) times\n",
    "                \n",
    "                numbers = list(range(K))\n",
    "                numbers.remove(s)\n",
    "\n",
    "                # Sample N distinct integers from the list\n",
    "                a = tuple(random.sample(numbers, N))\n",
    "                #i = random.sample(numbers,1)[0] #choose random action\n",
    "                    \n",
    "            else:  # Exploit 1-e(t) times\n",
    "                a= tuple(np.argpartition(-np.array(P[s]), N)[:N])\n",
    "                #i = np.argmax(Q[s]) #choose greedily the action with highest Q value\n",
    "            # a = action_table[s][a_idx]  \n",
    "\n",
    "            if (all_recommendations_are_relevant(a,s)):\n",
    "            \n",
    "                if np.random.uniform() < alpha:  # If all recommended items are relevant\n",
    "                    i = int(np.random.choice(a))  # Pick a random item from relevant recommended items\n",
    "                else:  # If at least one recommended item is not relevant\n",
    "                    i = np.random.randint(K)  # Pick a random item\n",
    "            else:\n",
    "                i = np.random.randint(K)  # Pick a random item\n",
    "\n",
    "            if U[s][i]>u_min:\n",
    "        \n",
    "                reward = (1 - 2*Cost[i])\n",
    "            else:\n",
    "                \n",
    "                reward = -1\n",
    "            #reward = (1 - 2*Cost[i])\n",
    "            s_prime = i\n",
    "            if np.random.uniform() < q: #if user opt to terminate session\n",
    "                target = reward\n",
    "                Q[s][i] = Q[s][i] + learning_rate * ( target - Q[s][i] )\n",
    "                break\n",
    "            else:\n",
    "                P[s_prime],maxval = maximize_model(Q[s_prime],s_prime)\n",
    "                target = reward + gamma*maxval\n",
    "            Q[s][i] = Q[s][i] + learning_rate * ( target - Q[s][i] )\n",
    "            \n",
    "            s = s_prime\n",
    "        t+=1\n",
    "        epsilon = (t+1)**(-1/3)*(K*math.log(t+1))**(1/3)\n",
    "        #epsilon = 0.1\n",
    "        #learning_rate = learning_rate*(1/t)**(1/2)\n",
    "        \n",
    "        #if (np.max(np.abs(prev_Q - Q)) < delta and t>1000*K) or \n",
    "        if t > 100*K: #check if the new V estimate is close enough to the previous one;\n",
    "            break # if yes, finish loop\n",
    "        #prev_Q = Q.copy()\n",
    "    # print(Q)\n",
    "    # print(\"===================================================================================\")\n",
    "    # print(P)\n",
    "    return P\n",
    "\n",
    "\n",
    "\n",
    "# pi_Q_learning  =  np.zeros((K, N), dtype=np.int16)\n",
    "# print(U)\n",
    "# print(Cost)\n",
    "# print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "Q = SlateQ(1-q,1,0.01)\n",
    "\n",
    "pi_SlateQ = np.argpartition(Q, -N, axis=1)[:, -N:]\n",
    "# for s in range(K):\n",
    "#     #Q[s][s] = float('-inf')\n",
    "#     action = np.argmax(Q[s])\n",
    "#     pi_Q_learning[s] = action_table[s][action]\n",
    "\n",
    "print(pi_SlateQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cost for SlateQ:\n",
      "1.44118\n"
     ]
    }
   ],
   "source": [
    "def simulate_session(policy, max_steps=1000):\n",
    "    \"\"\"\n",
    "    Simulate a viewing session following a given policy\n",
    "\n",
    "    arguments:\n",
    "    policy to be simulated\n",
    "\n",
    "    returns:\n",
    "    total cost of the session\n",
    "    \n",
    "    \"\"\"\n",
    "    s = np.random.randint(K)  # random initial\n",
    "    cost_total = Cost[s]  \n",
    "    for _ in range(max_steps):\n",
    "        if np.random.uniform() < q:  # The user decides to quit\n",
    "            break\n",
    "\n",
    "        if (all_recommendations_are_relevant(policy[s],s)):\n",
    "            \n",
    "            if np.random.uniform() < alpha:  # If all recommended items are relevant\n",
    "                s_prime = int(np.random.choice(policy[s]))  # Pick a random item from relevant recommended items\n",
    "            else:  # If at least one recommended item is not relevant\n",
    "                s_prime = np.random.randint(K)  # Pick a random item\n",
    "        else:\n",
    "            s_prime = np.random.randint(K)  # Pick a random item\n",
    "        \n",
    "        s=s_prime\n",
    "        cost_total += Cost[s]  # Add the cost of the picked item\n",
    "    return cost_total\n",
    "\n",
    "def simulation(policy):\n",
    "    \"\"\"\n",
    "    function to run multiple sessions\n",
    "    \"\"\"\n",
    "    total_cost = 0\n",
    "    num_of_episodes=50000\n",
    "    for _ in range(num_of_episodes):\n",
    "        total_cost  += simulate_session(policy)\n",
    "\n",
    "    print(total_cost/num_of_episodes)\n",
    "\n",
    "# print(U)\n",
    "# print(Cost)\n",
    "# #print(P_opt1)\n",
    "# print(pi_SlateQ)\n",
    "\n",
    "print(\"average cost for SlateQ:\")\n",
    "simulation(pi_SlateQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
